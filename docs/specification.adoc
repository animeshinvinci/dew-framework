== 技术指标(TBD)

=== 可靠性

TBD

=== 性能

TBD


服务器基本情况介绍
    172.30.250.153
        cpu:4核
        内存:4G内存
        网络：内网

    172.30.249.186
        cpu:4核
        内存:4G内存
        网络:内网
        ps:有其它程序在跑暂用一定的内存空间可用内存2G左右

    172.30.249.183
        cpu:4核
        内存:4G
        网络:内网
        ps:有其它程序在跑暂用一定的内存空间可用内存2G左右

所有程序介绍:
    注册中心:registry[Eureka Server]
    网关:gateway[Zuul]
    对外服务接口:pressure-test-api
    具体服务实现:pressure-test-service

程序部署情况：
    在172.30.250.153部署
        Eureka Server 部署路径--->>>/home/release/apps/registry
        Zuul 部署路径--->>>/home/release/apps/gateway

    在172.30.249.186部署
        pressure-test-api 部署路径--->>>/opt/spring-cloud-client

    在172.30.249.183部署
        pressure-test-service 部署路径--->>>/opt/spring-cloud-service

程序中影响性能的参数

    1.四个程序tomcat的配置如下[全部相同]：
        server.tomcat.accept-count=1000
        server.tomcat.max-threads=1000
        server.tomcat.max-connections=2000

    2.Eureka Server其它参数：
        eureka.server.enable-self-preservation=false
        eureka.server.remote-region-fetch-thread-pool-size=500
        eureka.server.remote-region-read-timeout-ms=5000
        eureka.server.remote-region-total-connections=1000
        eureka.server.remote-region-total-connections-per-host=500

    3.gateway其它参数：
        eureka.host.max-per-route-connections=2000
        eureka.host.max-total-connections=2000

        zuul.host.maxTotalConnections=1000
        zuul.host.maxPerRouteConnections=1000
        zuul.semaphore.maxConcurrentRequests=1000
        zuul.semaphore.maxSemaphores=1000

        ribbon.MaxConnectionsPerHost=500
        ribbon.MaxTotalConnections=1000
        ribbon.PoolMaxThreads=1000
        ribbon.PoolMinThreads=500
        ribbon.ReadTimeout=6000
        ribbon.ConnectTimeout=6000

        hystrix.command.isolation.thread.timeoutInMilliseconds=10000

    4.pressure-test-api其它参数:
        eureka.host.max-per-route-connections=2000
        eureka.host.max-total-connections=2000

        ribbon.ServerListRefreshInterval=1000
        ribbon.MaxConnectionsPerHost=500
        ribbon.MaxTotalConnections=1000
        ribbon.PoolMaxThreads=1000
        ribbon.PoolMinThreads=500
        ribbon.ReadTimeout=6000
        ribbon.ConnectTimeout=6000

    5.pressure-test-service其它参数：
        eureka.host.max-per-route-connections=2000
        eureka.host.max-total-connections=2000

服务之间调用情况:
    gateway,pressure-test-api,pressure-test-service三者服务全部注册在registry中。
    测试发起，首先掉用gateway服务，蒋分发到pressure-test-api中，pressure-test-api调用pressure-test-service，最后将结果返回。
    ps:pressure-test-api 通过ribbon[负载均衡]来调用pressure-test-service

测试结果：

    测试条件:
        1.并发线程数:350
        2.持续运行10分钟
        3.模拟执行服务时间为200毫秒
    测试结果:
        总请求数:781372
        成功:100%
        Thoughput:1300/s
        Average:268
        Median:203
        90%line:211
        95%line:222
        99%line:3835
        Min:201
        Max:7272

    测试条件:
        1.并发线程数:250
        2.持续运行11分钟
        3.模拟执行服务时间为200毫秒
    测试结果:
        总请求数:811963
        成功:100%
        Thoughput:1225/s
        Average:203
        Median:203
        90%line:205
        95%line:210
        99%line:222
        Min:201
        Max:545

    测试条件:
        1.并发线程数:500
        2.持续运行10分钟
        3.模拟执行服务时间为200毫秒
    测试结果:
        总请求数:751614
        成功:100%
        Thoughput:1247/s
        Average:400
        Median:204
        90%line:231
        95%line:284
        99%line:7209
        Min:201
        Max:7569

    在业务处理时间为200毫秒，tomcat设置为1000线程的情况下，并发量为250比较合理。99%line也只有222毫秒。超过250的并发量，建议修改参数。

参数修改建议:

    参数具体参看：
    eureka-server:
    org.springframework.cloud:spring-cloud-netflix-eureka-server:1.3.1.RELEASE.jar/META-INF/spring-configuration-metadata.json
    eureka-client:
    org.springframework.cloud:spring-cloud-netflix-eureka-client:1.3.1.RELEASE.jar/META-INF/spring-configuration-metadata.json
    feign、ribbon、zuul:
    org.springframework.cloud:spring-cloud-netflix-core:1.3.1.RELEASE.jar/META-INF/spring-configuration-metadata.json
    Hystrix:
    https://github.com/Netflix/Hystrix/wiki/Configuration
    ribbon:
    参数名参考:https://github.com/Netflix/ribbon/blob/master/ribbon-core/src/main/java/com/netflix/client/config/CommonClientConfigKey.java#L83
    参数默认值:https://github.com/Netflix/ribbon/blob/3a707ec518a896053be44266dddc4c4f925f4e60/ribbon-core/src/main/java/com/netflix/client/config/DefaultClientConfigImpl.java#L331

    如果默认配置不能满足性能要求，首先调高所有服务的tomcat的线程配置。accept-count[可以等待请求数量],max-threads[最大并发数量],max-connections[最大链接数]
    调整了tomcat以后，使用到了ribbon服务的地方需要调整ribbon的连接数大小。然后调整zuul[网关]连接数池大小。

    当gateway[网关]中的ribbon的连接数没有调整的情况，测试结果中的Thoughput只能保持在200多，访问时长max异常的大。
    分析原因:gateway[网关]接收到请求以后，通过ribbon[负载均衡服务]去调用具体的服务。虽然gateway的tomcat能接受非常的多请求，但是ribbon线程数默认较小,很多请求在等待。
    这样导致max会异常的大。因为ribbon线程数默认较小，调用服务的线程数也较少，反应出来的情况就是服务的Thoughput并不是特别的高。Ps:实际上只需要调整MaxConnectionsPerHost,
    MaxTotalConnections两个参数，改问题就能解决，这里还是建议将Pool的参数也同等比例的调整放大比较合适。













